# adl-deep-dive

## Criteria for the Deep Dive on Kolmogorov–Arnold Networks (KANs)

- Discover topics that go beyond the lecture
- Show connections to the lecture content (where applicable)
- Choose a topic in teams of 2 students
- We will have a small “conference” at the end of the term
- Topics are organized in tracks.
- Important
- Connect with teams in your track and coordinate
- Show direct links to lecture content
- 15 minutes (3min questions), equal share of speaking time and preparation work
- Target audience: graduate students that took Advanced Deep Learning
- Coordinate with the teams in your tracks. Goal: No duplication of content.

---

## Track 6: **Exotic Architectures — Beyond the Transformer Paradigm**

**TODO** What overlaps do KANs have with the other exotic architectures?


### **Talk 1 – DeepONet: Learning Operators, Not Functions**
**Sources:**
[Lu et al., 2021 — *Learning Nonlinear Operators via Deep Neural Networks (DeepONet)*](https://arxiv.org/abs/1910.03193)

**Focus:**
Learns mappings between entire functions using a branch–trunk architecture. Pioneers operator learning for physics and PDEs.

---

### **Talk 2 – Fourier Neural Operators (FNO)**
**Sources:**
[Li et al., 2021 — *Fourier Neural Operator for Parametric PDEs*](https://arxiv.org/abs/2010.08895)

**Focus:**
Extends DeepONet with spectral learning using Fourier transforms. Efficiently learns function mappings in frequency space.

---

### **Talk 3 – Kolmogorov–Arnold Networks (KANs)**
**Sources:**
[Liu et al., 2024 — *Kolmogorov–Arnold Networks*](https://arxiv.org/abs/2404.19756)

**Focus:**
Implements the Kolmogorov–Arnold representation theorem with learnable univariate spline functions. Provides interpretable, function-based learning beyond weighted sums.

---

### **Talk 4 – Capsule Networks: Object-Centric Representation**
**Sources:**
[Hinton, Sabour & Frosst, 2018 — *Dynamic Routing Between Capsules*](https://arxiv.org/pdf/1710.09829)

**Focus:**
Encodes entities as capsules containing pose and state vectors. Models part–whole relationships and hierarchical visual reasoning.

---

### **Talk 5 – Spiking Neural Networks (SNNs)**
**Sources:**
[J. D. Nunes, M. Carvalho, D. Carneiro and J. S. Cardoso, "Spiking Neural Networks: A Survey](https://ieeexplore.ieee.org/document/9787485)

**Focus:**
Processes information through discrete spike events and membrane potentials. Biologically inspired and energy-efficient for neuromorphic hardware.

---

